# File: penguins_ai/scripts/benchmark_system.py

import time
import psutil
# import platform  # Unused import
import torch
# import tensorflow as tf  # Unused import
import xgboost as xgb
import numpy as np
# import pandas as pd  # Unused import
from sklearn.model_selection import train_test_split
import GPUtil
import cpuinfo

class SystemBenchmark:
    """Benchmark system and find optimal ML settings"""
    
    def __init__(self):
        self.results = {}
        
    def get_system_info(self):
        """Detect system capabilities"""
        print("üñ•Ô∏è SYSTEM INFORMATION")
        print("=" * 50)
        
        # CPU Info
        cpu_info = cpuinfo.get_cpu_info()
        print(f"CPU: {cpu_info['brand_raw']}")
        print(f"Cores: {psutil.cpu_count(logical=False)} physical, {psutil.cpu_count(logical=True)} logical")
        print(f"Frequency: {psutil.cpu_freq().current:.2f} MHz")
        
        # RAM Info
        ram = psutil.virtual_memory()
        print(f"\nRAM: {ram.total / (1024**3):.1f} GB")
        print(f"Available: {ram.available / (1024**3):.1f} GB")
        
        # GPU Info
        try:
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                print(f"\nGPU: {gpu.name}")
                print(f"Memory: {gpu.memoryTotal} MB")
                print(f"CUDA Available: {torch.cuda.is_available()}")
        except:
            print("\nGPU: Detection failed")
        
        return {
            'cpu_cores': psutil.cpu_count(logical=True),
            'ram_gb': ram.total / (1024**3),
            'gpu_available': torch.cuda.is_available()
        }
    
    def benchmark_xgboost(self, n_samples=100000):
        """Test XGBoost performance"""
        print("\n\nüîÑ BENCHMARKING XGBOOST")
        print("=" * 50)
        
        # Generate test data
        X = np.random.randn(n_samples, 20)
        y = np.random.randint(0, 2, n_samples)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
        
        results = {}
        
        # Test different thread counts
        for n_jobs in [1, 4, 8, 16, 20, 24, -1]:
            print(f"\nTesting with {n_jobs} threads...")
            
            model = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=8,
                n_jobs=n_jobs,
                verbosity=0
            )
            
            start = time.time()
            model.fit(X_train, y_train)
            train_time = time.time() - start
            
            results[n_jobs] = train_time
            print(f"Training time: {train_time:.2f}s")
        
        # Find optimal
        optimal_threads = min(results.keys(), key=lambda k: results[k])
        print(f"\n‚úÖ Optimal XGBoost threads: {optimal_threads}")
        
        return optimal_threads
    
    def benchmark_deep_learning(self):
        """Test TensorFlow/PyTorch GPU performance"""
        print("\n\nüîÑ BENCHMARKING DEEP LEARNING")
        print("=" * 50)
        
        if torch.cuda.is_available():
            # PyTorch GPU test
            print("\nPyTorch GPU Test:")
            device = torch.device('cuda')
            
            # Warm up GPU
            print("Warming up GPU...")
            for _ in range(10):
                a = torch.randn(1000, 1000).to(device)
                b = torch.randn(1000, 1000).to(device)
                c = torch.matmul(a, b)
            torch.cuda.synchronize()
            
            # Actual benchmark with better size
            size = 5000  # Reduced from 10000
            a = torch.randn(size, size).to(device)
            b = torch.randn(size, size).to(device)
            
            torch.cuda.synchronize()
            start = time.time()
            c = torch.matmul(a, b)
            torch.cuda.synchronize()
            gpu_time = time.time() - start
            
            print(f"GPU Matrix Multiplication ({size}x{size}): {gpu_time:.3f}s")
            
            # Compare with CPU
            a_cpu = torch.randn(size, size)
            b_cpu = torch.randn(size, size)
            
            start = time.time()
            c_cpu = torch.matmul(a_cpu, b_cpu)
            cpu_time = time.time() - start
            
            print(f"CPU Matrix Multiplication ({size}x{size}): {cpu_time:.3f}s")
            print(f"GPU Speedup: {cpu_time/gpu_time:.1f}x faster")
        else:
            print("‚ùå No GPU detected for deep learning")
    
    def generate_optimal_config(self):
        """Generate optimal configuration file"""
        info = self.get_system_info()
        xgb_threads = self.benchmark_xgboost()
        self.benchmark_deep_learning()
        
        config = f"""# File: penguins_ai/config/optimal_settings.py
# Generated by system benchmark

SYSTEM_OPTIMAL_CONFIG = {{
    # CPU Settings
    'xgboost_threads': {xgb_threads},
    'cpu_parallel_jobs': {min(info['cpu_cores'] - 4, 20)},  # Leave some for system
    
    # Memory Settings  
    'max_memory_gb': {int(info['ram_gb'] * 0.75)},  # Use 75% of RAM
    'batch_size': {2048 if info['gpu_available'] else 512},
    
    # Model Complexity (based on your powerful system)
    'xgboost_config': {{
        'n_estimators': 1000,  # More trees
        'max_depth': 12,       # Deeper trees
        'learning_rate': 0.01,
        'n_jobs': {xgb_threads}
    }},
    
    # GPU Settings
    'use_gpu': {info['gpu_available']},
    'gpu_memory_fraction': 0.8,  # Use 80% of GPU memory
    
    # Data Processing
    'chunk_size': 100000,  # Process large chunks
    'enable_parallel_processing': True
}}
"""
        
        # Create config directory if it doesn't exist
        import os
        os.makedirs('config', exist_ok=True)
        
        # Save config
        with open('config/optimal_settings.py', 'w') as f:
            f.write(config)
        
        print(f"\n\n‚úÖ Optimal configuration saved to config/optimal_settings.py")
        print("\nRECOMMENDATIONS:")
        print(f"1. Use {xgb_threads} threads for XGBoost")
        print(f"2. Process data in {int(info['ram_gb'] * 0.75)}GB chunks")
        print(f"3. {'Use GPU for deep learning models' if info['gpu_available'] else 'Use CPU-optimized models'}")

if __name__ == "__main__":
    benchmark = SystemBenchmark()
    benchmark.generate_optimal_config()